```{r}
library(stats)
library(stacomiR)
library(dplyr)
library(ggplot2)
library(forecast)
library(tidyr)
library(stringr)
```

```{r}
# import fish migration data
require(stacomiR)
data(package="stacomiR") # all fish migration datasets available

stacomi(database_expected=FALSE)    
```

Summed by week

```{r}
data("r_mig_interannual_vichy")
assign("r_mig_interannual_vichy",r_mig_interannual_vichy,envir=envir_stacomi)

df <- r_mig_interannual_vichy@data
df <- df %>% filter(bjo_labelquantite=="Effectif_total") %>%
  select(c(bjo_identifiant, bjo_dis_identifiant,
           bjo_annee, bjo_jour, bjo_valeur)) %>%
  # mutate(bjo_valeur = case_when(bjo_valeur < 0 ~ 0,
  #                               TRUE ~ bjo_valeur)) %>%
  rename(sample_id=bjo_identifiant, dc_id=bjo_dis_identifiant,
         year=bjo_annee, timestamp=bjo_jour, value=bjo_valeur)

df$week <- strftime(df$timestamp, format = "%V")
df <- df %>% group_by(week, year) %>%
  summarize(value = sum(value),
            timestamp = first(timestamp)) %>%
  ungroup() %>%
  arrange(timestamp)

years <- 1997:2012
year_weeks <- data.frame(year=rep(years, 53)) %>% arrange(year)
year_weeks$week <- rep(1:53, length(years))

imputed <- merge(year_weeks, df, by=c("year", "week"), all.x = TRUE)
imputed <- imputed %>% mutate(
    beginning = lubridate::ymd(str_c(year, "-01-01")),
    final_date = beginning + lubridate::weeks(sprintf("%02d", week)),
    month = format(final_date, "%m")
  ) %>% select(-c(beginning)) %>% group_by(month, year) %>%
  mutate(value = replace_na(value, mean(na.omit(value)))) %>% 
  ungroup() %>%
  mutate(value = replace_na(value, 0))

# Extract single feature we want to predict (and drop any NAs)
migrations <- imputed %>% select(c(timestamp, value))
migrations <- na.omit(migrations)  # Remove NAs
```

```{r}
# Visualize the time series
ggplot(migrations %>% filter(timestamp < "2000-05-21 01:00:00"), aes(x = timestamp, y = value)) +
  geom_line() +
  ggtitle('Fish Sightings History') +
  xlab('Time') +
  ylab('Sightings') +
  theme_minimal()
```

```{r}
# Lag and ACF Plots
# Creating lag features (to do the analysis manually)
for (i in 1:55) {
  migrations[, paste0('Lag_', i)] <- c(rep(NA, i), head(migrations$value, -i))
}

# Drop rows with missing values due to lagging
migrations <- na.omit(migrations)

# Autocorrelation Function
acf(migrations$value, main = "Sightings ACF Plot")
```

```{r}
lag = 50

# Split into training and test sets
train_size <- round(0.8 * nrow(migrations))
train_data <- migrations[1:train_size,]
test_data <- migrations[(train_size + 1):nrow(migrations),]

# Define y_train and y_test
y_train <- train_data$value
y_test <- test_data$value

# Confirm that Lag 10 still has a large correlation
cor(migrations$value, lag(migrations$value, n = lag), use = "complete.obs")
```

```{r}
# AR(30) model
X_train <- train_data %>% select(paste("Lag", 1:lag, sep = "_"))

# Fit AR(30) Model (OLS)
X_matrix <- as.matrix(cbind(1, X_train))  # Add intercept column (if desired)
y_vector <- as.matrix(y_train)
w <- solve(t(X_matrix) %*% X_matrix) %*% (t(X_matrix) %*% y_vector)

# Predict migration using AR(30)
y_pred <- numeric(length(y_test))
start <- as.matrix(tail(X_train, 1))

for (i in 1:length(y_test)) {
  y_pred[i] <- as.numeric(w[1] + start %*% as.matrix(w[2:(lag+1)]))
  start <- c(y_pred[i], start[1:(lag-1)])
}

# Observed vs predicted plot
plot(y_pred, y_test, ylab = "Observed Migration", xlab = "Predicted Migration", 
     main = "AR(30) Model Predictions")
abline(0, 1, col = "red")
```
```{r}
# Time series plot of actual vs predicted SO9
plot(test_data$timestamp, test_data$value, type = "l", col = "blue", lwd = 2, ylim = range(c(y_pred, test_data$value)), xlab = "date", ylab = "migration count", main = paste0("AR(",lag,") Model Predictions"))
lines(test_data$timestamp, y_pred, col = "red", lwd = 2, lty = 2)
legend("topleft", legend = c("Actual Migration", paste0("AR(",lag,") Predicted Migration")), col = c("blue", "red"), lty = c(1, 2), bty = "n")

```

Averaged by week

```{r}
data("r_mig_interannual_vichy")
assign("r_mig_interannual_vichy",r_mig_interannual_vichy,envir=envir_stacomi)

df <- r_mig_interannual_vichy@data
df <- df %>% filter(bjo_labelquantite=="Effectif_total") %>%
  select(c(bjo_identifiant, bjo_dis_identifiant,
           bjo_annee, bjo_jour, bjo_valeur)) %>%
  # mutate(bjo_valeur = case_when(bjo_valeur < 0 ~ 0,
  #                               TRUE ~ bjo_valeur)) %>%
  rename(sample_id=bjo_identifiant, dc_id=bjo_dis_identifiant,
         year=bjo_annee, timestamp=bjo_jour, value=bjo_valeur)

df$week <- strftime(df$timestamp, format = "%V")
df <- df %>% group_by(week, year) %>%
  summarize(value = mean(value),
            timestamp = first(timestamp)) %>% 
  ungroup() %>%
  arrange(timestamp)

years <- 1997:2012
year_weeks <- data.frame(year=rep(years, 53)) %>% arrange(year)
year_weeks$week <- rep(1:53, length(years))

imputed <- merge(year_weeks, df, by=c("year", "week"), all.x = TRUE)
imputed <- imputed %>% mutate(
    beginning = lubridate::ymd(str_c(year, "-01-01")),
    final_date = beginning + lubridate::weeks(sprintf("%02d", week)),
    month = format(final_date, "%m")
  ) %>% select(-c(beginning)) %>% group_by(month, year) %>%
  mutate(value = replace_na(value, mean(na.omit(value)))) %>% 
  ungroup() %>%
  mutate(value = replace_na(value, 0))

# Extract single feature we want to predict (and drop any NAs)
migrations <- imputed %>% select(c(timestamp, value))
migrations <- na.omit(migrations)  # Remove NAs
```

```{r}
# Visualize the time series
ggplot(migrations %>% filter(timestamp < "2000-05-21 01:00:00"), aes(x = timestamp, y = value)) +
  geom_line() +
  ggtitle('Fish Sightings History') +
  xlab('Time') +
  ylab('Sightings') +
  theme_minimal()
```

```{r}
# Lag and ACF Plots
# Creating lag features (to do the analysis manually)
for (i in 1:55) {
  migrations[, paste0('Lag_', i)] <- c(rep(NA, i), head(migrations$value, -i))
}

# Drop rows with missing values due to lagging
migrations <- na.omit(migrations)

# Autocorrelation Function
acf(migrations$value, main = "Sightings ACF Plot")
```

```{r}
lag = 52

# Split into training and test sets
train_size <- round(0.8 * nrow(migrations))
train_data <- migrations[1:train_size,]
test_data <- migrations[(train_size + 1):nrow(migrations),]

# Define y_train and y_test
y_train <- train_data$value
y_test <- test_data$value

# Confirm that Lag 10 still has a large correlation
cor(migrations$value, lag(migrations$value, n = lag), use = "complete.obs")
```

```{r}
# AR model
X_train <- train_data %>% select(paste("Lag", 1:lag, sep = "_"))

# Fit AR(p) Model (OLS)
X_matrix <- as.matrix(cbind(1, X_train))  # Add intercept column (if desired)
y_vector <- as.matrix(y_train)
w <- solve(t(X_matrix) %*% X_matrix) %*% (t(X_matrix) %*% y_vector)

# Predict migration using AR(p)
y_pred <- numeric(length(y_test))
start <- as.matrix(tail(X_train, 1))

for (i in 1:length(y_test)) {
  y_pred[i] <- as.numeric(w[1] + start %*% as.matrix(w[2:(lag+1)]))
  start <- c(y_pred[i], start[1:(lag-1)])
}

# Observed vs predicted plot
plot(y_pred, y_test, ylab = "Observed Migration", xlab = "Predicted Migration", 
     main = paste0("AR(",lag,") Model Predictions"))
abline(0, 1, col = "red")
```
```{r}
# Time series plot of actual vs predicted SO9
plot(test_data$timestamp, test_data$value, type = "l", col = "blue", lwd = 2, ylim = range(c(y_pred, test_data$value)), xlab = "date", ylab = "migration count", main = paste0("AR(",lag,") Model Predictions"))
lines(test_data$timestamp, y_pred, col = "red", lwd = 2, lty = 2)
legend("topleft", legend = c("Actual Migration", paste0("AR(",lag,") Predicted Migration")), col = c("blue", "red"), lty = c(1, 2), bty = "n")

```
```{r}
base_ma <- function(x, n, align = c("right", "center")) {
  align <- match.arg(align)
  if (align == "right") {
    side <- 1 
  } else if (align == "center") {
    side <- 2
  }
  as.numeric(stats::filter(x, rep(1 / n, n), sides = side))
}

data("r_mig_interannual_vichy")
assign("r_mig_interannual_vichy",r_mig_interannual_vichy,envir=envir_stacomi)

df <- r_mig_interannual_vichy@data
df <- df %>% filter(bjo_labelquantite=="Effectif_total") %>%
  select(c(bjo_identifiant, bjo_dis_identifiant,
           bjo_annee, bjo_jour, bjo_valeur)) %>%
  mutate(bjo_valeur = case_when(bjo_valeur < 0 ~ 0,
                                TRUE ~ bjo_valeur)) %>%
  rename(sample_id=bjo_identifiant, dc_id=bjo_dis_identifiant,
         year=bjo_annee, timestamp=bjo_jour, value=bjo_valeur)

df$ma <- base_ma(df$value, n = 10, align = "right")
df <- na.omit(df)

# Extract single feature we want to predict (and drop any NAs)
migrations <- df %>% select(c(timestamp, ma))
migrations <- na.omit(migrations)  # Remove NAs
```

```{r}
# Visualize the time series
ggplot(migrations %>% filter(timestamp < "2000-05-21 01:00:00"), aes(x = timestamp, y = ma)) +
  geom_line() +
  ggtitle('Fish Sightings History') +
  xlab('Time') +
  ylab('Sightings') +
  theme_minimal()
```

```{r}
# Lag and ACF Plots
# Creating lag features (to do the analysis manually)
for (i in 1:365) {
  migrations[, paste0('Lag_', i)] <- c(rep(NA, i), head(migrations$ma, -i))
}

# Drop rows with missing values due to lagging
migrations <- na.omit(migrations)

# Autocorrelation Function
acf(migrations$ma, main = "Sightings ACF Plot")
```

```{r}
lag = 365

# Split into training and test sets
train_size <- round(0.8 * nrow(migrations))
train_data <- migrations[1:train_size,]
test_data <- migrations[(train_size + 1):nrow(migrations),]

# Define y_train and y_test
y_train <- train_data$ma
y_test <- test_data$ma

# Confirm that Lag 10 still has a large correlation
cor(migrations$ma, lag(migrations$ma, n = lag), use = "complete.obs")
```

```{r}
# AR(30) model
X_train <- train_data %>% select(paste("Lag", 1:lag, sep = "_"))

# Fit AR(30) Model (OLS)
X_matrix <- as.matrix(cbind(1, X_train))  # Add intercept column (if desired)
y_vector <- as.matrix(y_train)
w <- solve(t(X_matrix) %*% X_matrix) %*% (t(X_matrix) %*% y_vector)

# Predict migration using AR(30)
y_pred <- numeric(length(y_test))
start <- as.matrix(tail(X_train, 1))

for (i in 1:length(y_test)) {
  y_pred[i] <- as.numeric(w[1] + start %*% as.matrix(w[2:(lag+1)]))
  start <- c(y_pred[i], start[1:(lag-1)])
}

# Observed vs predicted plot
plot(y_pred, y_test, ylab = "Observed Migration", xlab = "Predicted Migration", 
     main = "AR(30) Model Predictions")
abline(0, 1, col = "red")
```
```{r}
# Time series plot of actual vs predicted SO9
plot(test_data$timestamp, test_data$ma, type = "l", col = "blue", lwd = 2, ylim = range(c(y_pred, test_data$ma)), xlab = "date", ylab = "migration count", main = paste0("AR(",lag,") Model Predictions"))
lines(test_data$timestamp, y_pred, col = "red", lwd = 2, lty = 2)
legend("topleft", legend = c("Actual Migration", paste0("AR(",lag,") Predicted Migration")), col = c("blue", "red"), lty = c(1, 2), bty = "n")

```

```{r}
# Preprocessing steps
df <- r_mig_interannual_vichy@data
df <- df %>% filter(bjo_labelquantite=="Effectif_total") %>%
  select(c(bjo_identifiant, bjo_dis_identifiant,
           bjo_annee, bjo_jour, bjo_valeur)) %>%
    mutate(bjo_valeur = case_when(bjo_valeur < 0 ~ 1,
                                 TRUE ~ bjo_valeur)) %>%
  rename(sample_id=bjo_identifiant, dc_id=bjo_dis_identifiant,
         year=bjo_annee, timestamp=bjo_jour, value=bjo_valeur)

df$week <- strftime(df$timestamp, format = "%V")
df <- df %>% group_by(week, year) %>%
  summarize(value = sum(value),
            timestamp = first(timestamp)) %>% 
  ungroup() %>%
  arrange(timestamp)

years <- 1997:2012
year_weeks <- data.frame(year=rep(years, 52)) %>% arrange(year)
year_weeks$week <- rep(1:52, length(years))

imputed <- merge(year_weeks, df, by=c("year", "week"), all.x = TRUE)
imputed <- imputed %>% mutate(
    beginning = lubridate::ymd(str_c(year, "-01-01")),
    final_date = beginning + lubridate::weeks(sprintf("%02d", week)),
    month = format(final_date, "%m")
  ) %>% select(-c(beginning)) %>% group_by(month, year) %>%
  mutate(value = replace_na(value, mean(na.omit(value)))) %>% 
  ungroup() %>%
  mutate(value = replace_na(value, 0))

# Extract single feature we want to predict (and drop any NAs)
migrations <- imputed %>% select(c(timestamp, value))
migrations <- na.omit(migrations)  # Remove NAs
```


```{r}
# Split into training and test sets
train_size <- round(0.8 * nrow(migrations))
train_data <- migrations[1:train_size,]
test_data <- migrations[(train_size + 1):nrow(migrations),]

# Define y_train and y_test
y_train <- train_data
y_test <- test_data

y_train_ts <- ts(y_train, frequency=52)
y_train_ts <- y_train_ts[,"value"]

# Apply a transformation to stabilize variance before modeling
# Square root transformation is often good for count data
y_train_ts_transformed <- sqrt(y_train_ts)
```

```{r}
sarima_model <- auto.arima(y_train_ts_transformed, 
                          seasonal = TRUE,
                          stepwise = FALSE,
                          approximation = FALSE,
                          D = 1,              # Force seasonal differencing
                          max.P = 2,          # Allow higher order seasonal AR
                          max.Q = 2)          # Allow higher order seasonal MA
  
forecast_steps <- nrow(y_test)
y_test <- y_test$value

# Generate forecasts
sarima_forecast <- forecast(sarima_model, h = forecast_steps)

# Transform the forecasts back to the original scale
# Square the forecasts and prediction intervals
predicted_values <- sarima_forecast$mean^2
```


```{r}
# Grab max value to ensure that all y values are visible
max_value <- max(c(predicted_values, y_test), na.rm = TRUE)

plot(predicted_values, main = "SARIMA Forecast vs Actual", xlab = "Time", ylab = "Value", 
     col = "blue", lwd = 2, ylim = c(0, max_value + 10))  # Forecasted values in blue

# Add actual test data values to the plot (in red)
lines(ts(y_test, start = end(time(y_train_ts)) + c(0,1), frequency = 52), 
      col = "red", lwd = 2)

# Add a legend to distinguish between predicted and actual
legend("topleft", legend = c("Forecasted", "Actual"), col = c("blue", "red"), lty = 1, lwd = 2)
```


